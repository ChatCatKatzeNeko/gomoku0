{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2019)\n",
    "from collections import namedtuple\n",
    "from collections import deque\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "from pickle import Pickler, Unpickler\n",
    "import os, sys\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WinState = namedtuple('WinState', ['is_ended', 'winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS():\n",
    "    def __init__(self, game, wrapped_nnet, args):\n",
    "        self.game = game\n",
    "        self.wrapped_nnet = wrapped_nnet\n",
    "        self.args = args\n",
    "        \n",
    "        self.q_sa = {} # q(s,a) = Q value of taking action a at state s, avg win rate with penalty (values in the interval [-1,1])\n",
    "                       # e.g.: at state s take action a results 1 game won over 3, q_sa(s,a) = (1-1-1)/3 = -1/3\n",
    "        self.n_sa = {} # n(s,a) = number of games passing by state s and action a\n",
    "        self.n_s = {} # n(s) = number of games played including state s\n",
    "        \n",
    "        self.policies_s = {} # initial policies returned by the nnet\n",
    "        self.valid_moves_s = {} # all valid moves at state s\n",
    "        self.end_game_s = {} # if a game is ended or not \n",
    "        \n",
    "\n",
    "    '''\n",
    "    uses history statistic counts to \n",
    "    return a probabilistic vector of length nb_rows*nb_cols (flattened board)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def getActionSpaceProba(self, canonicalBoard, temperature=1, add_dirichlet_noise=True):\n",
    "        '''\n",
    "        ========\n",
    "        pipeline\n",
    "        ========\n",
    "        \n",
    "        # step 1: run simulations started from the given board\n",
    "        # step 2: update statistics of the given board\n",
    "        # step 3: calculate probability vector by the following formula\n",
    "        #         Pr(a|s) = n_sa(s,a)^(1/temperature) / sum(n_sa(s,a')^(1/temperature), for all a' in legal moves)\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        ''' step 1: '''\n",
    "        for i in range(self.args['MCTS_nb_simulations']):\n",
    "            self.search(canonicalBoard)\n",
    "        '''end step 1'''\n",
    "        \n",
    "        ''' step 2:'''\n",
    "        s = self.game.getStringRepresentation(canonicalBoard)\n",
    "        \n",
    "        # valid_pos: nb_rows * nb_cols binary array\n",
    "        valid_pos = self.game.getValidMoves(canonicalBoard)\n",
    "        \n",
    "        # counts: nb_rows * nb_cols array whose elements are node counts of each position\n",
    "        counts = [[self.n_sa[(s,(row, col))] if (s,(row, col)) in self.n_sa and valid_pos[row,col] else 0 \n",
    "                  for col in range(canonicalBoard.shape[1])]\n",
    "                 for row in range(canonicalBoard.shape[0])]\n",
    "        counts = np.array(counts)\n",
    "        ''' end step 2'''\n",
    "        \n",
    "        # diriclet noise: randomly pick a position among the valid ones and add a tiny value to its count\n",
    "        if add_dirichlet_noise:\n",
    "            nb_valid_pos = valid_pos.sum()\n",
    "            \n",
    "            # this allows to convert valid positions' matrix into an equi-probability matrix of valid moves\n",
    "            valid_pos = valid_pos / nb_valid_pos\n",
    "            idx = np.random.choice(canonicalBoard.shape[0]*canonicalBoard.shape[1], \n",
    "                                   p=np.ndarray.flatten(valid_pos))\n",
    "            # add a noise\n",
    "            counts[int(idx/canonicalBoard.shape[0]), np.mod(idx,canonicalBoard.shape[1])] += 1\n",
    "            \n",
    "        ''' step 3:'''\n",
    "        probas = np.zeros((canonicalBoard.shape[0]*canonicalBoard.shape[1],))\n",
    "        if temperature == 0:\n",
    "            probas[np.argmax(counts)] = 1\n",
    "            \n",
    "        else:\n",
    "            counts = counts ** (1/temperature)\n",
    "            probas = np.ndarray.flatten(counts/counts.sum())\n",
    "        ''' end step 3''' \n",
    "        \n",
    "        \n",
    "        return probas\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    returns simulation results guided by neural network and updates statistics of the search tree\n",
    "    '''\n",
    "    def search(self, canonicalBoard):\n",
    "        '''\n",
    "        ========\n",
    "        pipeline\n",
    "        ========\n",
    "        \n",
    "        # step 1: check if the current state is seen, if not, store whether it is an ending state\n",
    "        # step 2: check if the current state is an ending state, if is, return the winner from the opponent's point of view;\n",
    "                                                                 if not, next step.\n",
    "        # step 3: check if the current state is seen, if is, next step;\n",
    "                                                      if not, use the current neural network to predict the probability vector and the winner,\n",
    "                                                              store the information of the current state then return the predicted winner from  \n",
    "                                                              the opponent's point of view.\n",
    "        # step 4: develop the current state one step ahead by choosing the move that maximises the Q value (kind of reward function), move on \n",
    "                  to the next state, repeat step 1 (call search function recursively, recursion terminates when one of the stopping conditions\n",
    "                  is satisfied).\n",
    "        # step 5: increment the exploitation count of the current state\n",
    "        # step 6: check if the taken move is seen, if is, update the move's statistics;\n",
    "                                                   if not, initialise the move as child node of the current state\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        s = self.game.getStringRepresentation(canonicalBoard)\n",
    "        \n",
    "        ''' step 1: '''\n",
    "        # track the untracked game state\n",
    "        if s not in self.end_game_s:\n",
    "            self.end_game_s[s] = self.game.isEnded(canonicalBoard,1) # canonicalBoard is the board from player1's point of view\n",
    "        ''' end step 1'''\n",
    "        \n",
    "        ''' step 2: '''\n",
    "        # if the game is ended, return value\n",
    "        if self.end_game_s[s] != 0:  \n",
    "            return -self.end_game_s[s]\n",
    "        ''' end step 2'''\n",
    "        \n",
    "        ''' step 3: '''\n",
    "        # if s is a newly discovered leaf node, return value and store policies matrix\n",
    "        if s not in self.policies_s:\n",
    "            # policies and value are given by the neural network's prediction\n",
    "            self.policies_s[s], v = self.wrapped_nnet.predict(canonicalBoard) # v to be returned\n",
    "            self.policies_s[s] = self.policies_s[s].reshape(canonicalBoard.shape[0],canonicalBoard.shape[1])\n",
    "            \n",
    "            # a binomial array indicating if a position is valid or not\n",
    "            valid_moves = self.game.getValidMoves(canonicalBoard)\n",
    "            \n",
    "            # mask out the unvalid moves from policies matrix and renormalise it\n",
    "            self.policies_s[s] *= valid_moves\n",
    "            \n",
    "            # renormalise policies_s[s]\n",
    "            tmp_sum = self.policies_s[s].sum()\n",
    "            if tmp_sum > 0:\n",
    "                self.policies_s[s] /= tmp_sum\n",
    "            else:\n",
    "                print(\"Warning: all valid moves are masked. Check the neural net. \\n\")\n",
    "                self.policies_s[s] = valid_moves/valid_moves.sum()\n",
    "            \n",
    "            self.valid_moves_s[s] = valid_moves\n",
    "            self.n_s[s] = 0 # newly created leaf node\n",
    "            return -v\n",
    "        ''' end step 3 '''\n",
    "        \n",
    "        ''' step 4: '''\n",
    "        # if s is not a ongoing state, keep searching until return condition satisfied\n",
    "        valid_moves = self.valid_moves_s[s]\n",
    "        current_best = -np.inf\n",
    "        best_action = (-1,-1)\n",
    "        \n",
    "        valid_pos = np.where(valid_moves)\n",
    "        for row, col in zip(valid_pos[0], valid_pos[1]):\n",
    "            # calculate q value accordingly\n",
    "            if (s,(row, col)) in self.q_sa:\n",
    "                u = self.q_sa[(s,(row, col))] + self.args['MCTS_C'] * self.policies_s[s][row][col] * np.sqrt(self.n_s[s]) / (1 + self.n_sa[(s,(row, col))])\n",
    "            else:\n",
    "                u = self.args['MCTS_C'] * self.policies_s[s][row][col] * np.sqrt(self.n_s[s] + 0.000001)\n",
    "\n",
    "            if u > current_best:\n",
    "                current_best = u\n",
    "                best_action = (row, col)\n",
    "                    \n",
    "        next_s, next_player = self.game.getNextState(canonicalBoard, 1, best_action[0], best_action[1])\n",
    "        next_s = self.game.getCanonicalForm(next_s, next_player)\n",
    "        v = self.search(next_s)\n",
    "        ''' end step 4 '''\n",
    "        \n",
    "        ''' step 5: '''\n",
    "        # recursively update statistics of the search tree\n",
    "        self.n_s[s] += 1\n",
    "        ''' end step 5 '''\n",
    "        \n",
    "        ''' step 6: '''\n",
    "        # if the best action has never been played\n",
    "        if (s, best_action) not in self.q_sa:\n",
    "            self.q_sa[(s, best_action)] = v\n",
    "            self.n_sa[(s, best_action)] = 1\n",
    "            \n",
    "        # if the best action has already been played\n",
    "        else:\n",
    "            # take the average of the q values with its history\n",
    "            self.q_sa[(s, best_action)] = (v + self.n_sa[(s, best_action)] * self.q_sa[(s, best_action)]) / (self.n_sa[(s, best_action)] + 1)\n",
    "            # increment the count of the node\n",
    "            self.n_sa[(s, best_action)] += 1\n",
    "        ''' end step 6 '''  \n",
    "        \n",
    "        return -v\n",
    "      \n",
    "      \n",
    "    \n",
    "class Board():    \n",
    "    def __init__(self, nb_rows=15, nb_cols=15, win_length=5, stone_matrix=None):\n",
    "        self.nb_rows = nb_rows\n",
    "        self.nb_cols = nb_cols\n",
    "        self.win_length = win_length\n",
    "        if stone_matrix is None:\n",
    "            self.stone_matrix = np.zeros((self.nb_rows, self.nb_cols))\n",
    "            #self.stone_matrix[int(self.nb_rows/2),int(self.nb_cols/2)] = 1\n",
    "        else:\n",
    "            self.stone_matrix = stone_matrix\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.stone_matrix)\n",
    "    \n",
    "    def copyBoard(self, stone_matrix):\n",
    "        if stone_matrix is None:\n",
    "            stone_matrix = self.stone_matrix\n",
    "        return Board(stone_matrix=stone_matrix)\n",
    "    \n",
    "        \n",
    "    def addStone(self, row, col, player):\n",
    "        if self.stone_matrix[row,col] != 0:\n",
    "            raise ValueError(\"(%d, %d) taken.\" % (row, col))\n",
    "        self.stone_matrix[row,col] = player\n",
    "     \n",
    "    \n",
    "    def getValidMoves(self):\n",
    "        return self.stone_matrix == 0\n",
    "    \n",
    "    \n",
    "    def getWinState(self):\n",
    "        # first, check if one of the players wins\n",
    "        # second, check if tied\n",
    "        # last, game is still ongoing\n",
    "        \n",
    "        # 1st\n",
    "        for player in [-1,1]:\n",
    "            current_player_stones = np.array(self.stone_matrix == -player, dtype=int)\n",
    "            \n",
    "            if (self._straight5(current_player_stones) \n",
    "                or self._straight5(current_player_stones.transpose()) \n",
    "                or self._diag5(current_player_stones)):\n",
    "                \n",
    "                # if the opponent has more than 5 stones aligned, the opponent loses\n",
    "                if (self._straight5plus(current_player_stones) \n",
    "                    or self._straight5plus(current_player_stones.transpose()) \n",
    "                    or self._diag5plus(current_player_stones)):\n",
    "                    return WinState(True, player)\n",
    "                \n",
    "                return WinState(True, -player)\n",
    "        \n",
    "        # 2nd\n",
    "        if not self.getValidMoves().any():\n",
    "            return WinState(True, None)\n",
    "        \n",
    "        # finally\n",
    "        return WinState(False, None)\n",
    "    \n",
    "    \n",
    "    def _straight5(self, player_stones):\n",
    "        contiguous_stones_counts = [player_stones[i:(i+self.win_length), :].sum(axis=0) \n",
    "                                    for i in range(self.nb_rows-self.win_length+1)]\n",
    "        contiguous_stones_counts = np.array(contiguous_stones_counts)\n",
    "        aligned = (contiguous_stones_counts == self.win_length)\n",
    "        if aligned.any():\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def _straight5plus(self, player_stones):\n",
    "        contiguous_stones_counts = [player_stones[i:(i+self.win_length+1), :].sum(axis=0) \n",
    "                                    for i in range(self.nb_rows-self.win_length)]\n",
    "        contiguous_stones_counts = np.array(contiguous_stones_counts)\n",
    "        aligned = (contiguous_stones_counts > self.win_length)\n",
    "        if aligned.any():\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def _diag5(self, player_stones):\n",
    "        # slide a matrix of win_length over the board and check if there exists any diagonal or anti-diagonal \n",
    "        # sub-matrices. if it does, the game is won\n",
    "        for i in range(self.nb_rows - self.win_length + 1):\n",
    "            for j in range(self.nb_cols - self.win_length + 1):\n",
    "                # if diagonal or anti-diagonal exists\n",
    "                if (np.trace(player_stones[i:(i+self.win_length), j:(j+self.win_length)]) == self.win_length or\n",
    "                    np.trace(np.fliplr(player_stones[i:(i+self.win_length), j:(j+self.win_length)])) == self.win_length): \n",
    "                    return True \n",
    "        return False\n",
    "    \n",
    "    def _diag5plus(self, player_stones):\n",
    "        # slide a matrix of win_length+1 over the board and check if there exists any diagonal or anti-diagonal \n",
    "        # sub-matrices. if it does, the game is loss\n",
    "        for i in range(self.nb_rows - self.win_length):\n",
    "            for j in range(self.nb_cols - self.win_length):\n",
    "                # if diagonal or anti-diagonal exists\n",
    "                if (np.trace(player_stones[i:(i+self.win_length+1), j:(j+self.win_length+1)]) > self.win_length or\n",
    "                    np.trace(np.fliplr(player_stones[i:(i+self.win_length+1), j:(j+self.win_length+1)])) > self.win_length): \n",
    "                    return True \n",
    "        return False\n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "class Game():\n",
    "    def __init__(self, nb_rows=15, nb_cols=15, win_length=5, stone_matrix=None):\n",
    "        self._base_board = Board(nb_rows, nb_cols, win_length, stone_matrix)\n",
    "    \n",
    "    def getInitBoard(self):\n",
    "        return self._base_board.stone_matrix\n",
    "    \n",
    "    def getNextState(self, board, player, row, col):\n",
    "        board_cp = self._base_board.copyBoard(stone_matrix=np.copy(board))\n",
    "        board_cp.addStone(row, col, player)\n",
    "        return board_cp.stone_matrix, -player\n",
    "    \n",
    "    def getValidMoves(self, board):\n",
    "        return self._base_board.copyBoard(stone_matrix=board).getValidMoves()\n",
    "    \n",
    "    def getActionSpaceSize(self):\n",
    "        return self._base_board.nb_rows * self._base_board.nb_cols\n",
    "    \n",
    "    def isEnded(self, board, player):\n",
    "        board_new = self._base_board.copyBoard(stone_matrix=board)\n",
    "        win_state = board_new.getWinState()\n",
    "        \n",
    "        # if game ended\n",
    "        if win_state.is_ended:\n",
    "            # tie\n",
    "            if win_state.winner is None:\n",
    "                return 0.00001\n",
    "            # current player wins\n",
    "            elif win_state.winner == player:\n",
    "                return 1\n",
    "            # current player loses\n",
    "            elif win_state.winner == -player:\n",
    "                return -1\n",
    "            else:\n",
    "                raise ValueError('Unexpected winstate found: ', win_state)\n",
    "            \n",
    "        # if game continues\n",
    "        else:\n",
    "            return 0\n",
    "      \n",
    "    # keep player1's point of view\n",
    "    def getCanonicalForm(self, board, player):\n",
    "        return board * player\n",
    "    \n",
    "    def getStringRepresentation(self, board):\n",
    "        return str(board)\n",
    "    \n",
    "    # returns a list of symmetric states of the current board along with the policy matrix\n",
    "    def getSymmetries(self, board, pi):\n",
    "        # original board; left-right flipped board; upside-down board; \n",
    "        # left_right flipped upside down board;\n",
    "        # transposed board; left_right flipped transposed board; upside-down transposed board;\n",
    "        # left_right flipped upside down transposed board\n",
    "        pi = np.array(pi).reshape(board.shape[0],board.shape[1])\n",
    "        pi_T = np.transpose(pi)\n",
    "        \n",
    "        board_T = np.transpose(board)\n",
    "        \n",
    "        return [(board, np.ndarray.flatten(pi)), \n",
    "                (np.flip(board, axis=1), np.ndarray.flatten(np.flip(pi, axis=1))), (np.flip(board, axis=0), np.ndarray.flatten(np.flip(pi, axis=0))),\n",
    "                (np.flip(board), np.ndarray.flatten(np.flip(pi))),\n",
    "                (board_T, np.ndarray.flatten(pi_T)), \n",
    "                (np.flip(board_T, axis=1), np.ndarray.flatten(np.flip(pi_T, axis=1))), (np.flip(board_T, axis=0), np.ndarray.flatten(np.flip(pi_T, axis=0))),\n",
    "                (np.flip(board_T), np.ndarray.flatten(np.flip(pi_T)))]\n",
    "      \n",
    "      \n",
    "      \n",
    "class Coach():\n",
    "    def __init__(self, game, args): \n",
    "        self.game = game\n",
    "        \n",
    "        self.wrapped_nnet = NNetWrapper(game)\n",
    "        self.mcts = MCTS(game, self.wrapped_nnet, args)\n",
    "        \n",
    "        self.wrapped_prev_net = NNetWrapper(game)\n",
    "        \n",
    "        self.args = args\n",
    "        \n",
    "        self.trainExamplesHistory = []\n",
    "        self.skip_first_self_play = False\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    an episode is a from-start-to-end game\n",
    "    '''\n",
    "    def executeEpisode(self):\n",
    "        \n",
    "        trainEg = []\n",
    "        board = self.game.getInitBoard()\n",
    "        self.current_player = 1\n",
    "        episode_count = 0\n",
    "        \n",
    "        while True:\n",
    "            episode_count += 1\n",
    "            canonical_board = self.game.getCanonicalForm(board, self.current_player)\n",
    "            temperature = int(episode_count < self.args['COACH_temperature_threshold'])\n",
    "            \n",
    "            pi = self.mcts.getActionSpaceProba(canonical_board, temperature) # vector of length nb_rows * nb_cols\n",
    "            sym = self.game.getSymmetries(canonical_board, pi)\n",
    "            trainEg += [[b, self.current_player, p, None] for b,p in sym]   # p: vector of length nb_rows * nb_cols\n",
    "            \n",
    "            \n",
    "            \n",
    "            idx = np.random.choice(len(pi), p=pi)\n",
    "            row = int(idx/canonical_board.shape[0])\n",
    "            col = np.mod(idx, canonical_board.shape[0]) \n",
    "            \n",
    "            board, self.current_player = self.game.getNextState(board, self.current_player, row, col)\n",
    "            res = self.game.isEnded(board, self.current_player)\n",
    "            \n",
    "            if res != 0:\n",
    "                print(\"in Coach.executeEpisode, total steps taken %d\" % episode_count)\n",
    "                #       board   pi    val = 1 if current player wins otherwise -1\n",
    "                return [ (x[0], x[2], res) for x in trainEg ]\n",
    "            \n",
    "            \n",
    "            \n",
    "    def learn(self):\n",
    "        for i in range(1, self.args['COACH_nb_iter'] + 1):   # number of times to update the neural network\n",
    "            print(\"-------- iteration number %d --------\" % i)\n",
    "            if not self.skip_first_self_play or i > 1:\n",
    "                iterationEg = deque([], maxlen=self.args['COACH_max_length_of_queue'])\n",
    "                for eps in range(self.args['COACH_nb_episode']):   # number of self-played games, used as training data\n",
    "                    print(\"in Coach.learn, episode %d\" % (eps + 1))\n",
    "                    \n",
    "                    # for each game, initialise a new search tree\n",
    "                    self.mcts = MCTS(self.game, self.wrapped_nnet, self.args)\n",
    "                    iterationEg += self.executeEpisode()\n",
    "                    \n",
    "                self.trainExamplesHistory.append(iterationEg)\n",
    "            \n",
    "            while len(self.trainExamplesHistory) > self.args['COACH_nb_iters_for_training_history']:\n",
    "                print(\"length of trainExamplesHistory: %d, remove the oldest training examples.\" % len(self.trainExamplesHistory))\n",
    "                self.trainExamplesHistory.pop(0)\n",
    "                \n",
    "            self.saveTrainExamples(i-1)\n",
    "            \n",
    "            # merge generated examples in to a list (trainEg) and shuffle it\n",
    "            trainEg = []\n",
    "            for eg in self.trainExamplesHistory:\n",
    "                trainEg.extend(eg)\n",
    "            shuffle(trainEg)\n",
    "            \n",
    "            # make a copy of the model that is used to predict probabilities and value in MCTS before training it\n",
    "            self.wrapped_nnet.saveCheckpoint(folder=self.args['NNET_checkpoint'], filename='temp.ckpt')\n",
    "            self.wrapped_prev_net.loadCheckpoint(folder=self.args['NNET_checkpoint'], filename='temp.ckpt')\n",
    "            \n",
    "            \n",
    "            # train the model\n",
    "            print(\"training the neural network...\")\n",
    "            self.wrapped_nnet.train(trainEg)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"Pit against the old neural network\")\n",
    "            # new network as player 2\n",
    "            prev_mcts = MCTS(self.game, self.wrapped_prev_net, self.args)\n",
    "            new_mcts = MCTS(self.game, self.wrapped_nnet, self.args)\n",
    "            arena1st = Arena(lambda x: np.argmax(prev_mcts.getActionSpaceProba(x, temperature=0, add_dirichlet_noise=True)),\n",
    "                             lambda x: np.argmax(new_mcts.getActionSpaceProba(x, temperature=0, add_dirichlet_noise=True)),\n",
    "                             game=self.game)\n",
    "            prev_wins_1st, new_wins_1st, draws_1st = arena1st.playGames(self.args['ARENA_nb_games'], verbose=False)\n",
    "            \n",
    "            # new network as player 1\n",
    "            prev_mcts = MCTS(self.game, self.wrapped_prev_net, self.args)\n",
    "            new_mcts = MCTS(self.game, self.wrapped_nnet, self.args)\n",
    "            arena2nd = Arena(lambda x: np.argmax(new_mcts.getActionSpaceProba(x, temperature=0, add_dirichlet_noise=True)),\n",
    "                             lambda x: np.argmax(prev_mcts.getActionSpaceProba(x, temperature=0, add_dirichlet_noise=True)),\n",
    "                             game=self.game)\n",
    "            new_wins_2nd, prev_wins_2nd, draws_2nd = arena2nd.playGames(self.args['ARENA_nb_games'], verbose=False)\n",
    "            \n",
    "            prev_wins = prev_wins_1st + prev_wins_2nd\n",
    "            new_wins = new_wins_1st + new_wins_2nd\n",
    "            print(\"previous model won %d games, new model won %d games, total game played: %d\" % \n",
    "                  (prev_wins, new_wins, \n",
    "                   prev_wins + new_wins + draws_1st + draws_2nd))\n",
    "            \n",
    "            # if the new player is not much stronger, do not update\n",
    "            if (prev_wins + new_wins == 0) or (new_wins / (prev_wins + new_wins)  < self.args['COACH_update_threshold']):\n",
    "                print(\"Reject new model\")\n",
    "                self.wrapped_nnet.loadCheckpoint(folder=self.args['NNET_checkpoint'], filename='temp.ckpt')\n",
    "            else:\n",
    "                print(\"Model updated\")\n",
    "                self.wrapped_nnet.saveCheckpoint(folder=self.args['NNET_checkpoint'], filename=self.getCheckpointFile(i))\n",
    "                self.wrapped_nnet.saveCheckpoint(folder=self.args['NNET_checkpoint'], filename='best.ckpt')\n",
    "                self.saveTrainExamples(99999) # 99999 for the best examples\n",
    "    \n",
    "   \n",
    "    def saveTrainExamples(self, iteration):\n",
    "        folder = self.args['COACH_load_folder_file']\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        filename = os.path.join(folder, self.getCheckpointFile(iteration)+\".examples\")\n",
    "        with open(filename, \"wb+\") as f:\n",
    "            Pickler(f).dump(self.trainExamplesHistory)\n",
    "        f.closed\n",
    "                                   \n",
    "                                   \n",
    "    def getCheckpointFile(self, iteration):\n",
    "        return \"check_pt_%d.ckpt\" % iteration\n",
    "    \n",
    "    def loadTrainExamples(self):\n",
    "        \n",
    "        modelFile = os.path.join(self.args['COACH_load_folder_file'], self.getCheckpointFile(99999)) \n",
    "        examplesFile = modelFile + \".examples\"\n",
    "        if not os.path.isfile(examplesFile):\n",
    "            print(examplesFile)\n",
    "            r = input(\"File with trainExamples not found. Continue? [y|n]\")\n",
    "            if r != \"y\":\n",
    "                sys.exit()\n",
    "        else:\n",
    "            print(\"File with trainExamples found\")\n",
    "            with open(examplesFile, \"rb\") as f:\n",
    "                self.trainExamplesHistory = Unpickler(f).load()\n",
    "            f.closed\n",
    "            # examples based on the model were already collected (loaded)\n",
    "            self.skip_first_self_play = True\n",
    "    \n",
    "    \n",
    "    \n",
    "class NNet():\n",
    "    def __init__(self, game, args):\n",
    "        self.board_x = game._base_board.nb_rows\n",
    "        self.board_y = game._base_board.nb_cols\n",
    "        \n",
    "        self.action_size = game.getActionSpaceSize()\n",
    "        self.args = args\n",
    "        \n",
    "        Relu = tf.nn.relu\n",
    "        Tanh = tf.nn.tanh\n",
    "        Batchnormalisation = tf.layers.batch_normalization\n",
    "        Dropout = tf.layers.dropout\n",
    "        Dense = tf.layers.dense\n",
    "        \n",
    "        self.graph = tf.Graph()\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            self.input_board = tf.placeholder(tf.float32, shape=[None, self.board_x, self.board_y])\n",
    "            self.dropout = tf.placeholder(tf.float32)\n",
    "            self.is_training = tf.placeholder(tf.bool, name=\"is_training\")\n",
    "            \n",
    "            x_image = tf.reshape(self.input_board, [-1, self.board_x, self.board_y, 1])\n",
    "            \n",
    "            h_conv1 = Relu(Batchnormalisation(self.conv2d(x_image, args['NNET_nb_channels'], [4,4], 'same'), axis=3, training=self.is_training))\n",
    "            h_conv2 = Relu(Batchnormalisation(self.conv2d(h_conv1, args['NNET_nb_channels'], [4,4], 'same'), axis=3, training=self.is_training))\n",
    "            \n",
    "            h_conv3 = Relu(Batchnormalisation(self.conv2d(h_conv2, args['NNET_nb_channels'], [3,3], 'valid'), axis=3, training=self.is_training))\n",
    "            h_conv4 = Relu(Batchnormalisation(self.conv2d(h_conv3, int(args['NNET_nb_channels']/2), [3,3], 'valid'), axis=3, training=self.is_training))\n",
    "            h_conv5 = Relu(Batchnormalisation(self.conv2d(h_conv4, int(args['NNET_nb_channels']/4), [2,2], 'valid'), axis=3, training=self.is_training))\n",
    "            \n",
    "            h_conv5_flat = tf.reshape(h_conv5, [-1, int(args['NNET_nb_channels']/4) * (self.board_x - 5) * (self.board_y - 5)])\n",
    "            \n",
    "            s_fc1 = Dropout(Relu(Batchnormalisation(Dense(h_conv5_flat, 900), axis=1, training=self.is_training)), rate=self.dropout)\n",
    "            s_fc2 = Dropout(Relu(Batchnormalisation(Dense(s_fc1, 450), axis=1, training=self.is_training)), rate=self.dropout)\n",
    "            \n",
    "            self.pi = Dense(s_fc2, self.action_size)\n",
    "            self.proba = tf.nn.softmax(self.pi)\n",
    "            self.val = Tanh(Dense(s_fc2, 1))\n",
    "            \n",
    "            self.calculateLoss()\n",
    "            \n",
    "    def conv2d(self, x, out_channels, kernel_size, padding):\n",
    "        return tf.layers.conv2d(x, out_channels, kernel_size=kernel_size, padding=padding,\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False))\n",
    "\n",
    "    def calculateLoss(self):\n",
    "        self.target_pi = tf.placeholder(tf.float32, shape=[None, self.action_size])\n",
    "        self.target_val = tf.placeholder(tf.float32, shape=[None])\n",
    "        \n",
    "        self.loss_pi = tf.losses.softmax_cross_entropy(onehot_labels=self.target_pi, logits=self.pi) \n",
    "        self.loss_val = tf.losses.mean_squared_error(labels=self.target_val, predictions=tf.reshape(self.val, [-1,]))\n",
    "        \n",
    "        self.total_loss = self.loss_pi + self.loss_val\n",
    "        \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            self.train_step = tf.train.AdamOptimizer(self.args['NNET_lr']).minimize(self.total_loss)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "class NNetWrapper():\n",
    "    def __init__(self, game):\n",
    "        self.nnet = NNet(game, args)\n",
    "        self.game = game\n",
    "        self.board_x = game._base_board.nb_rows\n",
    "        self.board_y = game._base_board.nb_cols\n",
    "        self.nb_valid_moves = game.getActionSpaceSize()\n",
    "        \n",
    "        self.sess = tf.Session(graph=self.nnet.graph)\n",
    "        self.saver = None\n",
    "        \n",
    "        with tf.Session() as temp_sess:\n",
    "            temp_sess.run(tf.global_variables_initializer())\n",
    "        self.sess.run(tf.variables_initializer(self.nnet.graph.get_collection('variables')))\n",
    "        \n",
    "    def train(self, examples):\n",
    "        for epoch in range(self.nnet.args['NNET_epochs']):\n",
    "            batch_idx = 0\n",
    "            pi_losses = []\n",
    "            val_losses = []\n",
    "            \n",
    "            \n",
    "            while batch_idx < len(examples)/self.nnet.args['NNET_batch_size']:\n",
    "                sample_idx = np.random.randint(len(examples), size=self.nnet.args['NNET_batch_size'])               \n",
    "                board_samples, pi_samples, val_samples = list(zip(*[examples[i] for i in sample_idx]))\n",
    "                \n",
    "                input_dict = { \n",
    "                               self.nnet.input_board : board_samples,\n",
    "                               self.nnet.target_pi   : pi_samples,\n",
    "                               self.nnet.target_val  : val_samples,\n",
    "                               self.nnet.dropout     : self.nnet.args['NNET_dropout'],\n",
    "                               self.nnet.is_training : True\n",
    "                             }\n",
    "                \n",
    "                self.sess.run(self.nnet.train_step, feed_dict=input_dict)\n",
    "            \n",
    "                pi_loss = self.sess.run(self.nnet.loss_pi, feed_dict=input_dict) \n",
    "                val_loss = self.sess.run(self.nnet.loss_val, feed_dict=input_dict)\n",
    "                \n",
    "                pi_losses.append(pi_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "                batch_idx += 1\n",
    "            \n",
    "            #'''\n",
    "            tmp_pi_losses = []\n",
    "            tmp_val_losses = []\n",
    "            tmp_pi_losses += pi_losses\n",
    "            tmp_val_losses += val_losses\n",
    "            if np.mod(epoch+1,5) == 0:\n",
    "                plt.subplots(figsize=(20,8))\n",
    "                plt.subplot(1,2,1)\n",
    "                plt.plot(np.arange(len(tmp_pi_losses)), tmp_pi_losses, '-o')\n",
    "                plt.xlabel(\"iterations\")\n",
    "                plt.ylabel(\"soft max cross entropy loss\")\n",
    "                \n",
    "                plt.subplot(1,2,2)\n",
    "                plt.plot(np.arange(len(tmp_val_losses)), tmp_val_losses, '-*')\n",
    "                plt.xlabel(\"iterations\")\n",
    "                plt.ylabel(\"MSE value loss\")\n",
    "                plt.show()\n",
    "                \n",
    "                tmp_pi_losses = []\n",
    "                tmp_val_losses = []\n",
    "            #'''\n",
    "\n",
    "    def predict(self, board):\n",
    "        board = board[np.newaxis, :, :]\n",
    "        input_dict = {\n",
    "                        self.nnet.input_board : board,\n",
    "                        self.nnet.dropout     : 0,\n",
    "                        self.nnet.is_training : False\n",
    "                     }\n",
    "        proba = self.sess.run(self.nnet.proba, feed_dict=input_dict)\n",
    "        val = self.sess.run(self.nnet.val, feed_dict=input_dict)\n",
    "        \n",
    "        return proba[0], val[0]\n",
    "    \n",
    "    \n",
    "    def saveCheckpoint(self, folder='checkpoint', filename='checkpoint.ckpt'):\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        if not os.path.exists(folder):\n",
    "            print(\"Checkpoint Directory does not exist! Making directory {}\".format(folder))\n",
    "            os.mkdir(folder)\n",
    "        \n",
    "        if self.saver == None:\n",
    "            self.saver = tf.train.Saver(self.nnet.graph.get_collection('variables'))\n",
    "        with self.nnet.graph.as_default():\n",
    "            self.saver.save(self.sess, filepath)\n",
    "\n",
    "    def loadCheckpoint(self, folder='checkpoint', filename='checkpoint.ckpt'):\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        \n",
    "        if not os.path.exists(filepath + '.meta'):\n",
    "            raise ValueError(\"No model in path {}\".format(filepath))\n",
    "        with self.nnet.graph.as_default():\n",
    "            self.saver = tf.train.Saver()\n",
    "            self.saver.restore(self.sess, filepath)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "class HumanPlayer():\n",
    "    def __init__(self, game):\n",
    "        self.game = game\n",
    "        \n",
    "    def play(self, board):\n",
    "        valid_moves = self.game.getValidMoves(board)\n",
    "        row, col = -1, -1\n",
    "        while True:\n",
    "            resign = input(\"resign (y|n)? \")\n",
    "            if resign == 'y':\n",
    "                return row, col, True\n",
    "            \n",
    "            row = int(input(\"row number? \"))\n",
    "            col = int(input(\"column number? \"))\n",
    "            \n",
    "            if valid_moves[row-1, col-1]:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid move\")\n",
    "        return row-1, col-1, False\n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "class MachinePlayer():\n",
    "    def __init__(self, game, args):\n",
    "        self.game = game\n",
    "        self.wrapped_nnet = NNetWrapper(game)\n",
    "        self.args = args\n",
    "        self.wrapped_nnet.loadCheckpoint(folder=self.args['NNET_checkpoint'], filename='best.ckpt')\n",
    "        \n",
    "    def play(self, board):\n",
    "        \"\"\" return the best neural network's prediction \"\"\"\n",
    "        row, col = -1, -1\n",
    "        mcts = MCTS(self.game, self.wrapped_nnet, self.args)\n",
    "        pi = mcts.getActionSpaceProba(board, temperature=0)\n",
    "        if pi.max() > 0:\n",
    "            pos = np.argmax(pi)\n",
    "            row = int(pos / board.shape[0])\n",
    "            col = np.mod(pos, board.shape[1])\n",
    "        \n",
    "        return row, col\n",
    "\n",
    "      \n",
    "\n",
    "class Arena():\n",
    "    def __init__(self, player1, player2, game):\n",
    "        self.player1 = player1 # function that takes board as input and outputs an action\n",
    "        self.player2 = player2 # function that takes board as input and outputs an action\n",
    "        self.game = game       # game obj\n",
    "        \n",
    "    \n",
    "    def humanVsMachine(self):\n",
    "        # players[0] = player2, computer; players[1] = player1, human\n",
    "        # player1 is numerated as 1, player2 is numerated as -1\n",
    "        players = [self.player2, self.player1]\n",
    "        current_player = 1\n",
    "        board = self.game.getInitBoard()\n",
    "        \n",
    "        while self.game.isEnded(board, current_player) == 0:\n",
    "            # human player's turn\n",
    "            if current_player == 1:\n",
    "                print(\"your turn: \")\n",
    "                displayBoard(board)\n",
    "                row, col, resign = players[1](board)\n",
    "                \n",
    "                if resign:\n",
    "                    print(\"\\n\\n\\n\\nGame over\")\n",
    "                    print(\"Human resigns\")\n",
    "                    break\n",
    "                    \n",
    "            # computer's turn\n",
    "            else:\n",
    "                print(\"computer's turn:\")\n",
    "                row, col = players[0](self.game.getCanonicalForm(board, current_player))\n",
    "                \n",
    "                if row < 0 or col < 0:\n",
    "                    print(\"Computer resigns\")\n",
    "                    break\n",
    "                \n",
    "            valid_moves = self.game.getValidMoves(board)        \n",
    "            if valid_moves[row, col]:\n",
    "                print(\"action taken by player %d: (%d, %d)\" % (current_player, row+1, col+1))\n",
    "                board, current_player = self.game.getNextState(board, current_player, row, col)\n",
    "            \n",
    "            else:\n",
    "                print(\"\\n\\n\\ninvalid move: (:d, :d), \\ncheck the neural net or game settings.\\n\\n\\n\" % (row, col))\n",
    "                break\n",
    "        print(\"\\n\\n\\n\\nGame over, result:\")\n",
    "        displayBoard(board)\n",
    "        print(\"Winner: %d\" % (2 * int(self.game.isEnded(board, 1) == 1) - 1))\n",
    "\n",
    "        \n",
    "    def playGame(self, verbose=False):\n",
    "        # players[0] = player2, players[1] = player1\n",
    "        # player1 is numerated as 1, player2 is numerated as -1\n",
    "        players = [self.player2, self.player1]\n",
    "        current_player = 1\n",
    "        nb_iter = 0\n",
    "        board = self.game.getInitBoard()\n",
    "        \n",
    "        while self.game.isEnded(board, current_player) == 0:\n",
    "            nb_iter += 1\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"\\nTurn #%d, current player: %d\" % (nb_iter, current_player))\n",
    "                displayBoard(board)\n",
    "                \n",
    "\n",
    "            #           max is here to make sure when player = -1, we take the 0th element of the list \"players\"\n",
    "            player_fct = players[max(current_player, 0)]\n",
    "            pos = player_fct(self.game.getCanonicalForm(board, current_player))\n",
    "            row, col = int(pos/board.shape[0]), np.mod(pos, board.shape[1])\n",
    "            valid_moves = self.game.getValidMoves(board)\n",
    "            if valid_moves[row, col]:\n",
    "                print(\"action taken by player %d: (%d, %d)\" % (current_player, row+1, col+1))\n",
    "            board, current_player = self.game.getNextState(board, current_player, row, col)\n",
    "            \n",
    "        \n",
    "        print(\"Game over, result:\")\n",
    "        print(\"Winner: %d\" % self.game.isEnded(board, 1))\n",
    "        displayBoard(board)\n",
    "       \n",
    "        return self.game.isEnded(board, 1)\n",
    "    \n",
    "    def playGames(self, nb_games, verbose=False):\n",
    "        p1won = 0\n",
    "        p2won = 0\n",
    "        draws = 0\n",
    "        eps = 0\n",
    "        \n",
    "        for game in range(nb_games):\n",
    "            print(\"in Arena.playGames, playing... round %d\" % (game + 1))\n",
    "            res = self.playGame(verbose=verbose)\n",
    "            if res == 1:\n",
    "                p1won += 1\n",
    "            elif res == -1:\n",
    "                p2won += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "        \n",
    "        return p1won, p2won, draws\n",
    "         \n",
    "      \n",
    "      \n",
    "    \n",
    "def displayBoard(stone_matrix):\n",
    "    # player 1: black stone, player -1: white stone\n",
    "    piece = {0: \" \", 1: u\"\\u25cf\", -1: u\"\\u25cb\"}\n",
    "\n",
    "    # define board's header: \"  1 2 3 ... 15\"\n",
    "    header = \"    {0}\".format(\"   \".join(str(i) for i in range(1, 10)))\n",
    "    header += \"  {0}\".format(\"  \".join(str(i) for i in range(10, stone_matrix.shape[1] + 1)))\n",
    "    \n",
    "    # define board's bar: \"  +-----...----+\"\n",
    "    bar = \"  +{0}+\".format(\"-\"*(4*stone_matrix.shape[1]-1))\n",
    "    \n",
    "    # define board's rows\n",
    "    row_file = [str(i+1) + u\" | {0} |\".format(u\" | \".join(piece[x] for x in row)) \n",
    "                for i,row in enumerate(stone_matrix[:9,:])]\n",
    "    row_file += [str(i+10) + u\"| {0} |\".format(u\" | \".join(piece[x] for x in row)) \n",
    "                 for i,row in enumerate(stone_matrix[9:,:])]\n",
    "    \n",
    "    # assemble up\n",
    "    board = (\"\\n\" + bar + \"\\n\").join(row_file)\n",
    "    board = u\"\\n\".join((header, bar, board, bar, header))\n",
    "\n",
    "    print(board)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'MCTS_C': 2,                  \n",
    "        'MCTS_nb_simulations': 500, \n",
    "        \n",
    "        'COACH_temperature_threshold': 30, \n",
    "        'COACH_update_threshold': 0.55,\n",
    "        'COACH_max_length_of_queue': 2000000,\n",
    "        'COACH_load_folder_file': './gomoku0_v1/examples/',\n",
    "        'COACH_nb_iters_for_training_history': 12, \n",
    "        'COACH_nb_episode': 8,                   \n",
    "        'COACH_nb_iter': 300,  \n",
    "        \n",
    "        'NNET_lr': 0.003,\n",
    "        'NNET_dropout': 0.3,\n",
    "        'NNET_batch_size': 256,                   \n",
    "        'NNET_nb_channels': 512,\n",
    "        'NNET_checkpoint': './gomoku0_v1/',\n",
    "        'NNET_epochs': 15, \n",
    "        \n",
    "        'ARENA_nb_games': 5,     \n",
    "        'load_model': True\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./gomoku0_v1/best.ckpt\n",
      "Load trainExamples from file\n",
      "File with trainExamples found\n",
      "-------- iteration number 1 --------\n",
      "INFO:tensorflow:Restoring parameters from ./gomoku0_v1/temp.ckpt\n",
      "training the neural network...\n"
     ]
    }
   ],
   "source": [
    "g = Game(nb_rows=10, nb_cols=10)\n",
    "nnet = NNetWrapper(g)\n",
    "\n",
    "if args['load_model']:\n",
    "    nnet.loadCheckpoint(folder=args['NNET_checkpoint'], filename='best.ckpt')\n",
    "    \n",
    "c = Coach(g, args) \n",
    "if args['load_model']:\n",
    "    print(\"Load trainExamples from file\")\n",
    "    c.loadTrainExamples()\n",
    "c.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./gomoku0_v1/best.ckpt\n",
      "your turn: \n",
      "    1   2   3   4   5   6   7   8   9  10\n",
      "  +---------------------------------------+\n",
      "1 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "2 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "3 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "4 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "5 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "6 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "7 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "8 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "9 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "10|   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "    1   2   3   4   5   6   7   8   9  10\n",
      "resign (y|n)? n\n",
      "row number? 5\n",
      "column number? 5\n",
      "action taken by player 1: (5, 5)\n",
      "computer's turn:\n",
      "action taken by player -1: (6, 1)\n",
      "your turn: \n",
      "    1   2   3   4   5   6   7   8   9  10\n",
      "  +---------------------------------------+\n",
      "1 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "2 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "3 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "4 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "5 |   |   |   |   | ● |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "6 | ○ |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "7 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "8 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "9 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "10|   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "    1   2   3   4   5   6   7   8   9  10\n",
      "resign (y|n)? n\n",
      "row number? 4\n",
      "column number? 4\n",
      "action taken by player 1: (4, 4)\n",
      "computer's turn:\n",
      "action taken by player -1: (4, 8)\n",
      "your turn: \n",
      "    1   2   3   4   5   6   7   8   9  10\n",
      "  +---------------------------------------+\n",
      "1 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "2 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "3 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "4 |   |   |   | ● |   |   |   | ○ |   |   |\n",
      "  +---------------------------------------+\n",
      "5 |   |   |   |   | ● |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "6 | ○ |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "7 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "8 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "9 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "10|   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "    1   2   3   4   5   6   7   8   9  10\n",
      "resign (y|n)? n\n",
      "row number? 6\n",
      "column number? 6\n",
      "action taken by player 1: (6, 6)\n",
      "computer's turn:\n",
      "action taken by player -1: (3, 1)\n",
      "your turn: \n",
      "    1   2   3   4   5   6   7   8   9  10\n",
      "  +---------------------------------------+\n",
      "1 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "2 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "3 | ○ |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "4 |   |   |   | ● |   |   |   | ○ |   |   |\n",
      "  +---------------------------------------+\n",
      "5 |   |   |   |   | ● |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "6 | ○ |   |   |   |   | ● |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "7 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "8 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "9 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "10|   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "    1   2   3   4   5   6   7   8   9  10\n",
      "resign (y|n)? n\n",
      "row number? 7\n",
      "column number? 7\n",
      "action taken by player 1: (7, 7)\n",
      "computer's turn:\n",
      "action taken by player -1: (6, 9)\n",
      "your turn: \n",
      "    1   2   3   4   5   6   7   8   9  10\n",
      "  +---------------------------------------+\n",
      "1 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "2 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "3 | ○ |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "4 |   |   |   | ● |   |   |   | ○ |   |   |\n",
      "  +---------------------------------------+\n",
      "5 |   |   |   |   | ● |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "6 | ○ |   |   |   |   | ● |   |   | ○ |   |\n",
      "  +---------------------------------------+\n",
      "7 |   |   |   |   |   |   | ● |   |   |   |\n",
      "  +---------------------------------------+\n",
      "8 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "9 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "10|   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "    1   2   3   4   5   6   7   8   9  10\n",
      "resign (y|n)? n\n",
      "row number? 8\n",
      "column number? 8\n",
      "action taken by player 1: (8, 8)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Game over, result:\n",
      "    1   2   3   4   5   6   7   8   9  10\n",
      "  +---------------------------------------+\n",
      "1 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "2 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "3 | ○ |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "4 |   |   |   | ● |   |   |   | ○ |   |   |\n",
      "  +---------------------------------------+\n",
      "5 |   |   |   |   | ● |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "6 | ○ |   |   |   |   | ● |   |   | ○ |   |\n",
      "  +---------------------------------------+\n",
      "7 |   |   |   |   |   |   | ● |   |   |   |\n",
      "  +---------------------------------------+\n",
      "8 |   |   |   |   |   |   |   | ● |   |   |\n",
      "  +---------------------------------------+\n",
      "9 |   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "10|   |   |   |   |   |   |   |   |   |   |\n",
      "  +---------------------------------------+\n",
      "    1   2   3   4   5   6   7   8   9  10\n",
      "Winner: 1\n"
     ]
    }
   ],
   "source": [
    "board = Board(nb_rows=10, nb_cols=10)\n",
    "renju = Game(nb_rows=10, nb_cols=10)\n",
    "me = HumanPlayer(renju)\n",
    "computer = MachinePlayer(renju,args)\n",
    "fct_me = (lambda x: me.play(x))\n",
    "fct_pc = (lambda x: computer.play(x))\n",
    "pit = Arena(fct_me, fct_pc, renju)\n",
    "pit.humanVsMachine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
